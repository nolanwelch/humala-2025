{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882885ad-b7d9-4586-a3e6-7d1dcb17544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31106c79-39ad-4a5e-878a-1e80edaa2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model', 'stimulus_number', 'acceptability_rating'], dtype='object')        stimulus_number  acceptability_rating\n",
      "count       720.000000            720.000000\n",
      "mean        122.750000              5.238889\n",
      "std          35.522623              1.629403\n",
      "min          79.000000              1.000000\n",
      "25%          90.750000              4.000000\n",
      "50%         116.000000              5.000000\n",
      "75%         148.000000              7.000000\n",
      "max         180.000000              7.000000\n",
      "Index(['participant', 'age', 'gender', 'education', 'aoa_english',\n",
      "       'aoa_spanish', 'cultural_id', 'blp', 'blp_history_english',\n",
      "       'blp_history_spanish', 'blp_use_english', 'blp_use_spanish',\n",
      "       'blp_proficiency_english', 'blp_proficiency_spanish',\n",
      "       'blp_attitudes_english', 'blp_attitudes_spanish', 'proficiency_english',\n",
      "       'proficiency_spanish', 'lextale_english', 'lextale_spanish', 'section',\n",
      "       'language', 'stimulus_number', 'structure', 'condition',\n",
      "       'lexicalization', 'rating'],\n",
      "      dtype='object')        participant          age  aoa_english  aoa_spanish          blp  \\\n",
      "count  1008.000000  1008.000000  1008.000000  1008.000000  1008.000000   \n",
      "mean   5108.428571    28.952381     2.523810     0.428571    40.149000   \n",
      "std    2379.056956     5.216820     2.443285     1.137454    39.616396   \n",
      "min    1522.000000    19.000000     0.000000     0.000000   -62.567000   \n",
      "25%    2943.000000    25.000000     0.000000     0.000000    23.248000   \n",
      "50%    4623.000000    31.000000     3.000000     0.000000    40.506000   \n",
      "75%    6176.000000    33.000000     5.000000     0.000000    61.028000   \n",
      "max    9915.000000    38.000000     7.000000     5.000000   128.043000   \n",
      "\n",
      "       blp_history_english  blp_history_spanish  blp_use_english  \\\n",
      "count          1008.000000          1008.000000      1008.000000   \n",
      "mean             98.761905            73.476190        33.809524   \n",
      "std              14.064360            16.658359         5.236362   \n",
      "min              64.000000            44.500000        21.000000   \n",
      "25%              89.000000            63.000000        30.000000   \n",
      "50%             103.000000            74.000000        35.000000   \n",
      "75%             110.000000            86.000000        37.000000   \n",
      "max             118.000000           101.000000        43.000000   \n",
      "\n",
      "       blp_use_spanish  blp_proficiency_english  blp_proficiency_spanish  \\\n",
      "count      1008.000000              1008.000000              1008.000000   \n",
      "mean         16.928571                22.666667                17.809524   \n",
      "std           8.543066                 1.459142                 3.789316   \n",
      "min           1.500000                20.000000                12.000000   \n",
      "25%          11.000000                21.000000                14.000000   \n",
      "50%          18.000000                23.000000                19.000000   \n",
      "75%          23.000000                24.000000                21.000000   \n",
      "max          35.500000                24.000000                24.000000   \n",
      "\n",
      "       blp_attitudes_english  blp_attitudes_spanish  proficiency_english  \\\n",
      "count            1008.000000            1008.000000          1008.000000   \n",
      "mean               21.285714              21.619048            36.238095   \n",
      "std                 3.508779               3.200936             2.224459   \n",
      "min                10.000000              10.000000            30.000000   \n",
      "25%                19.000000              21.000000            36.000000   \n",
      "50%                22.000000              22.000000            37.000000   \n",
      "75%                24.000000              24.000000            37.000000   \n",
      "max                24.000000              24.000000            39.000000   \n",
      "\n",
      "       proficiency_spanish  lextale_english  lextale_spanish  stimulus_number  \\\n",
      "count          1008.000000      1008.000000      1008.000000      1008.000000   \n",
      "mean             38.285714        82.916667        20.142857       122.750000   \n",
      "std               6.980588        20.569112        16.728079        35.515567   \n",
      "min              22.000000         0.000000        -1.000000        79.000000   \n",
      "25%              36.000000        75.000000        10.000000        90.750000   \n",
      "50%              38.000000        87.500000        12.000000       116.000000   \n",
      "75%              45.000000        96.250000        35.000000       148.000000   \n",
      "max              47.000000       100.000000        52.000000       180.000000   \n",
      "\n",
      "            rating  \n",
      "count  1008.000000  \n",
      "mean      6.512897  \n",
      "std       1.362657  \n",
      "min       1.000000  \n",
      "25%       7.000000  \n",
      "50%       7.000000  \n",
      "75%       7.000000  \n",
      "max       7.000000  \n"
     ]
    }
   ],
   "source": [
    "llm_ajt = pd.read_csv(\"../results.csv\")\n",
    "# Take median of three scores for LLM AJT responses\n",
    "llm_ajt = llm_ajt.groupby([\"model\", \"stimulus_number\"])[\"acceptability_rating\"].median().reset_index()\n",
    "\n",
    "human_ajt = pd.read_csv(\"../human-results.csv\")\n",
    "\n",
    "# Limit to utterances rated by both LLM and human annotators\n",
    "shared_stimulus_ids = set(llm_ajt[\"stimulus_number\"]).intersection(set(human_ajt[\"stimulus_number\"]))\n",
    "llm_ajt = llm_ajt[llm_ajt[\"stimulus_number\"].isin(shared_stimulus_ids)]\n",
    "human_ajt = human_ajt[human_ajt[\"stimulus_number\"].isin(shared_stimulus_ids)]\n",
    "\n",
    "print(llm_ajt.columns, llm_ajt.describe())\n",
    "print(human_ajt.columns, human_ajt.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdab267-7ef6-48ef-8fea-0f1ef4993cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairwise_preferences(df, annotator_col, stimulus_col, rating_col):\n",
    "    \"\"\"\n",
    "    Generate pairwise preferences for each annotator\n",
    "    \"\"\"\n",
    "    preferences = []\n",
    "    \n",
    "    for annotator in df[annotator_col].unique():\n",
    "        annotator_data = df[df[annotator_col] == annotator]\n",
    "        \n",
    "        # Get all pairs of stimuli rated by this annotator\n",
    "        for i, row1 in annotator_data.iterrows():\n",
    "            for j, row2 in annotator_data.iterrows():\n",
    "                if i >= j:  # Avoid duplicates and self-comparisons\n",
    "                    continue\n",
    "                \n",
    "                stimulus_i = row1[stimulus_col]\n",
    "                stimulus_j = row2[stimulus_col]\n",
    "                rating_i = row1[rating_col]\n",
    "                rating_j = row2[rating_col]\n",
    "                \n",
    "                # Skip ties\n",
    "                if rating_i == rating_j:\n",
    "                    continue\n",
    "                \n",
    "                # Record preference\n",
    "                if rating_i > rating_j:\n",
    "                    preferences.append({\n",
    "                        'annotator_id': annotator,\n",
    "                        'stimulus_i': stimulus_i,\n",
    "                        'stimulus_j': stimulus_j,\n",
    "                        'preference': f\"{stimulus_i}>{stimulus_j}\"\n",
    "                    })\n",
    "                else:\n",
    "                    preferences.append({\n",
    "                        'annotator_id': annotator,\n",
    "                        'stimulus_i': stimulus_i,\n",
    "                        'stimulus_j': stimulus_j,\n",
    "                        'preference': f\"{stimulus_j}>{stimulus_i}\"\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2300e80-dc8f-4a7f-b1e4-31ecc0c961de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_agreement(preferences_df):\n",
    "    \"\"\"\n",
    "    Calculate pairwise agreement within the group\n",
    "    \"\"\"\n",
    "    # Find stimulus pairs that multiple annotators evaluated\n",
    "    pair_counts = preferences_df.groupby(['stimulus_i', 'stimulus_j']).size()\n",
    "    shared_pairs = pair_counts[pair_counts > 1].index\n",
    "    \n",
    "    agreements = []\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    for stimulus_i, stimulus_j in shared_pairs:\n",
    "        pair_prefs = preferences_df[\n",
    "            (preferences_df['stimulus_i'] == stimulus_i) & \n",
    "            (preferences_df['stimulus_j'] == stimulus_j)\n",
    "        ]\n",
    "        \n",
    "        if len(pair_prefs) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Check agreement for all annotator pairs who rated this stimulus pair\n",
    "        annotators = pair_prefs['annotator_id'].tolist()\n",
    "        preferences = pair_prefs['preference'].tolist()\n",
    "        \n",
    "        for i in range(len(annotators)):\n",
    "            for j in range(i + 1, len(annotators)):\n",
    "                total_comparisons += 1\n",
    "                if preferences[i] == preferences[j]:\n",
    "                    agreements.append(1)\n",
    "                else:\n",
    "                    agreements.append(0)\n",
    "    \n",
    "    if total_comparisons == 0:\n",
    "        return 0.0, 0\n",
    "    \n",
    "    agreement_rate = np.mean(agreements)\n",
    "    return agreement_rate, total_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8db88c-0bd2-41fd-8256-9e986d4b7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_group_agreements(human_prefs, llm_prefs):\n",
    "    \"\"\"\n",
    "    Compare group-level agreement scores\n",
    "    \"\"\"\n",
    "    human_agreement, human_comps = calculate_pairwise_agreement(human_prefs)\n",
    "    llm_agreement, llm_comps = calculate_pairwise_agreement(llm_prefs)\n",
    "    \n",
    "    print(f\"Human Agreement: {human_agreement:.3f} ({human_comps} comparisons)\")\n",
    "    print(f\"LLM Agreement: {llm_agreement:.3f} ({llm_comps} comparisons)\")\n",
    "    print(f\"Difference: {llm_agreement - human_agreement:.3f}\")\n",
    "    \n",
    "    return human_agreement, llm_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35ee3f3-64f4-4c7e-a2a4-883e36f70777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_agreement(prefs_df):\n",
    "    \"\"\"Helper function for bootstrap resampling\"\"\"\n",
    "    # Resample annotators with replacement\n",
    "    annotators = prefs_df['annotator_id'].unique()\n",
    "    sampled_annotators = np.random.choice(annotators, size=len(annotators), replace=True)\n",
    "    \n",
    "    # Create bootstrap sample\n",
    "    bootstrap_prefs = []\n",
    "    for annotator in sampled_annotators:\n",
    "        annotator_prefs = prefs_df[prefs_df['annotator_id'] == annotator].copy()\n",
    "        bootstrap_prefs.append(annotator_prefs)\n",
    "    \n",
    "    if bootstrap_prefs:\n",
    "        bootstrap_df = pd.concat(bootstrap_prefs, ignore_index=True)\n",
    "        agreement, _ = calculate_pairwise_agreement(bootstrap_df)\n",
    "        return agreement\n",
    "    return 0.0\n",
    "\n",
    "def bootstrap_iteration(args):\n",
    "    \"\"\"Single bootstrap iteration - must be at module level for multiprocessing\"\"\"\n",
    "    human_prefs, llm_prefs, seed = args\n",
    "    np.random.seed(seed)\n",
    "    human_boot = bootstrap_agreement(human_prefs)\n",
    "    llm_boot = bootstrap_agreement(llm_prefs)\n",
    "    return human_boot, llm_boot\n",
    "\n",
    "def bootstrap_significance_test(human_prefs, llm_prefs, n_bootstrap=1000, n_cores=6):\n",
    "    \"\"\"\n",
    "    Step 4: Statistical significance testing via bootstrap (parallelized)\n",
    "    \"\"\"\n",
    "    from multiprocessing import Pool\n",
    "    try:\n",
    "        from tqdm.auto import tqdm\n",
    "        tqdm_available = True\n",
    "    except ImportError:\n",
    "        tqdm_available = False\n",
    "        print(\"tqdm not available, running without progress bar\")\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args_list = [(human_prefs, llm_prefs, i) for i in range(n_bootstrap)]\n",
    "    \n",
    "    # Run bootstrap iterations in parallel with progress bar\n",
    "    with Pool(n_cores) as pool:\n",
    "        if tqdm_available:\n",
    "            results = list(tqdm(pool.imap(bootstrap_iteration, args_list), \n",
    "                              total=n_bootstrap, \n",
    "                              desc=\"Bootstrap iterations\"))\n",
    "        else:\n",
    "            results = pool.map(bootstrap_iteration, args_list)\n",
    "            print(f\"Completed {n_bootstrap} bootstrap iterations\")\n",
    "    \n",
    "    # Unpack results\n",
    "    human_boots, llm_boots = zip(*results)\n",
    "    human_boots = list(human_boots)\n",
    "    llm_boots = list(llm_boots)\n",
    "    \n",
    "    # Calculate difference distribution\n",
    "    diff_boots = np.array(llm_boots) - np.array(human_boots)\n",
    "    \n",
    "    # Two-tailed p-value\n",
    "    observed_diff = np.mean(llm_boots) - np.mean(human_boots)\n",
    "    p_value = np.mean(np.abs(diff_boots) >= np.abs(observed_diff))\n",
    "    \n",
    "    print(f\"Bootstrap p-value: {p_value:.3f}\")\n",
    "    print(f\"95% CI for difference: [{np.percentile(diff_boots, 2.5):.3f}, {np.percentile(diff_boots, 97.5):.3f}]\")\n",
    "    \n",
    "    return p_value, diff_boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ed9e16-3ea0-4381-baf4-6c1f323036bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate pairwise preferences\n",
    "human_prefs = generate_pairwise_preferences(\n",
    "    human_ajt, 'participant', 'stimulus_number', 'rating'\n",
    ")\n",
    "llm_prefs = generate_pairwise_preferences(\n",
    "    llm_ajt, 'model', 'stimulus_number', 'acceptability_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14d5769-0ba9-4926-909f-8d9962ad9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Agreement: 0.672 (16342 comparisons)\n",
      "LLM Agreement: 0.866 (60052 comparisons)\n",
      "Difference: 0.193\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Compare agreements\n",
    "human_agreement, llm_agreement = compare_group_agreements(human_prefs, llm_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dab1190-d759-4e78-ad53-5fcf594b675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f88a2320f04e46b5e8c7d8240e93c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap iterations:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap p-value: 0.502\n",
      "95% CI for difference: [0.077, 0.229]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.502),\n",
       " array([0.21670358, 0.1173837 , 0.14321031, 0.19686647, 0.20435964,\n",
       "        0.18550199, 0.2107745 , 0.19803433, 0.14682387, 0.14907066,\n",
       "        0.16543062, 0.1817052 , 0.1557842 , 0.13083612, 0.15727408,\n",
       "        0.19447326, 0.10860588, 0.17652082, 0.0831419 , 0.07718239,\n",
       "        0.22514517, 0.21399122, 0.16583236, 0.15834233, 0.14247425,\n",
       "        0.18074066, 0.2252591 , 0.17690553, 0.11319351, 0.1958681 ,\n",
       "        0.13396077, 0.15003976, 0.09448314, 0.15561152, 0.18486094,\n",
       "        0.14480757, 0.16761729, 0.08411716, 0.22448345, 0.12800722,\n",
       "        0.16312736, 0.16346455, 0.20750253, 0.12292501, 0.10691937,\n",
       "        0.17734833, 0.05695194, 0.15422835, 0.19848603, 0.15675815,\n",
       "        0.20081492, 0.14268835, 0.06983843, 0.18171205, 0.17996832,\n",
       "        0.22278148, 0.1643945 , 0.13290053, 0.1350899 , 0.13566995,\n",
       "        0.14227682, 0.15244832, 0.10059158, 0.15472301, 0.1934317 ,\n",
       "        0.22346849, 0.18383774, 0.102064  , 0.15474983, 0.15190232,\n",
       "        0.20478537, 0.17689525, 0.16892051, 0.15705846, 0.1161284 ,\n",
       "        0.1721106 , 0.19653323, 0.16719826, 0.1463845 , 0.18180482,\n",
       "        0.22884329, 0.14758983, 0.13217992, 0.14587908, 0.15806173,\n",
       "        0.16672105, 0.1572151 , 0.13874624, 0.20598135, 0.16686255,\n",
       "        0.15321213, 0.07880992, 0.15508812, 0.16794356, 0.21642536,\n",
       "        0.19443321, 0.09695824, 0.11458446, 0.14923242, 0.13853949,\n",
       "        0.20806003, 0.14520561, 0.17792101, 0.17040095, 0.16060995,\n",
       "        0.13880372, 0.14271208, 0.21338852, 0.1762392 , 0.20828709,\n",
       "        0.17407962, 0.11141668, 0.16103363, 0.14854747, 0.14743491,\n",
       "        0.21814356, 0.09665511, 0.06790683, 0.12995618, 0.12723427,\n",
       "        0.19662989, 0.16752872, 0.20822315, 0.11792034, 0.15356272,\n",
       "        0.10384077, 0.15285074, 0.14110057, 0.14210754, 0.16434944,\n",
       "        0.16023143, 0.1844202 , 0.17257933, 0.18269823, 0.16425884,\n",
       "        0.1587443 , 0.13322747, 0.17145597, 0.18297443, 0.19353578,\n",
       "        0.19940162, 0.1559764 , 0.12650887, 0.25181928, 0.03292165,\n",
       "        0.10902997, 0.17095508, 0.07414019, 0.18206091, 0.08051678,\n",
       "        0.09636342, 0.11922794, 0.11122107, 0.22468272, 0.16171559,\n",
       "        0.17532904, 0.12962992, 0.10707655, 0.05079722, 0.13026015,\n",
       "        0.12689055, 0.16654435, 0.1344471 , 0.22129679, 0.13584194,\n",
       "        0.16735753, 0.18000966, 0.1132514 , 0.21837305, 0.12970473,\n",
       "        0.13396623, 0.17541848, 0.15515163, 0.09078815, 0.07818105,\n",
       "        0.10580381, 0.14076813, 0.16979256, 0.18402722, 0.18203381,\n",
       "        0.12090957, 0.1768209 , 0.2283131 , 0.157691  , 0.13663489,\n",
       "        0.19529536, 0.15684254, 0.1169175 , 0.15573972, 0.18732685,\n",
       "        0.17311663, 0.15800435, 0.12437032, 0.12180988, 0.22350563,\n",
       "        0.15029434, 0.10951413, 0.18091125, 0.16776092, 0.12997373,\n",
       "        0.20935517, 0.14439697, 0.18510539, 0.15326114, 0.17674354,\n",
       "        0.11260971, 0.15356309, 0.15999714, 0.18150092, 0.18605087,\n",
       "        0.11561553, 0.21889166, 0.1914586 , 0.19700755, 0.18005225,\n",
       "        0.09902327, 0.1615459 , 0.20438114, 0.16002645, 0.13593743,\n",
       "        0.17761851, 0.12747839, 0.14140168, 0.16217206, 0.11371602,\n",
       "        0.18932217, 0.13500586, 0.21786606, 0.11534711, 0.16553553,\n",
       "        0.14968225, 0.12142368, 0.06359735, 0.1271888 , 0.15603035,\n",
       "        0.13560879, 0.18138025, 0.18346155, 0.1672245 , 0.1530258 ,\n",
       "        0.13188889, 0.22168554, 0.12500824, 0.15276843, 0.05558858,\n",
       "        0.13347307, 0.16498902, 0.14975673, 0.07936492, 0.14440132,\n",
       "        0.15587791, 0.12493395, 0.12393111, 0.18046572, 0.09940775,\n",
       "        0.15885102, 0.17690127, 0.15001692, 0.15372357, 0.05454239,\n",
       "        0.15994648, 0.11798323, 0.15177625, 0.23142663, 0.19994269,\n",
       "        0.15167368, 0.13329147, 0.20601137, 0.23201218, 0.13163892,\n",
       "        0.15508125, 0.21245086, 0.23582337, 0.18787911, 0.23201479,\n",
       "        0.13344938, 0.19667331, 0.10901101, 0.20010261, 0.18773316,\n",
       "        0.20668449, 0.14122613, 0.14711703, 0.13041087, 0.14754424,\n",
       "        0.14485426, 0.18016894, 0.03322783, 0.06506537, 0.21227835,\n",
       "        0.1750875 , 0.25379221, 0.12845236, 0.14390221, 0.16823615,\n",
       "        0.14134719, 0.15417412, 0.18989228, 0.18533176, 0.15383442,\n",
       "        0.11335702, 0.23067277, 0.13388859, 0.126355  , 0.17624169,\n",
       "        0.10357999, 0.18153287, 0.26719615, 0.14797717, 0.13550836,\n",
       "        0.15733222, 0.13696669, 0.18967259, 0.17510571, 0.18210849,\n",
       "        0.10817522, 0.18014436, 0.13318623, 0.10293384, 0.16648211,\n",
       "        0.17726035, 0.14492763, 0.11132829, 0.16519638, 0.12055274,\n",
       "        0.09719467, 0.15703023, 0.11524653, 0.18934393, 0.19558231,\n",
       "        0.12903841, 0.18446541, 0.10810502, 0.0815405 , 0.16723945,\n",
       "        0.11521517, 0.14899881, 0.12693681, 0.19995992, 0.16421751,\n",
       "        0.17190772, 0.17658569, 0.13584697, 0.15386075, 0.0801088 ,\n",
       "        0.18507839, 0.13911672, 0.14470519, 0.22321427, 0.17873777,\n",
       "        0.11350329, 0.15302211, 0.17089528, 0.17441716, 0.14388062,\n",
       "        0.08545372, 0.16100106, 0.20075749, 0.14964048, 0.10401205,\n",
       "        0.17302505, 0.13079951, 0.14803298, 0.170946  , 0.111331  ,\n",
       "        0.15877563, 0.187724  , 0.14266469, 0.16648707, 0.20557625,\n",
       "        0.10314698, 0.1630486 , 0.17432764, 0.13452916, 0.14614074,\n",
       "        0.15324821, 0.21211503, 0.14372952, 0.13532993, 0.16460167,\n",
       "        0.21561487, 0.16008315, 0.18144303, 0.17849341, 0.15090869,\n",
       "        0.12080746, 0.15275883, 0.17445164, 0.14182614, 0.19363955,\n",
       "        0.20315751, 0.16874574, 0.12444842, 0.18261489, 0.15695582,\n",
       "        0.20879463, 0.18941075, 0.11712335, 0.09628795, 0.12644799,\n",
       "        0.1496058 , 0.17087022, 0.12920886, 0.17685887, 0.09854055,\n",
       "        0.11161974, 0.17017267, 0.17233613, 0.10868648, 0.20038271,\n",
       "        0.16770431, 0.23280191, 0.12190463, 0.19589179, 0.10206954,\n",
       "        0.11853819, 0.23813804, 0.15970687, 0.22083872, 0.18128359,\n",
       "        0.15576622, 0.2031672 , 0.10191369, 0.17333807, 0.19012053,\n",
       "        0.16786514, 0.19690691, 0.19255171, 0.15113639, 0.16119566,\n",
       "        0.16273349, 0.14512401, 0.1911466 , 0.11765904, 0.14218089,\n",
       "        0.17370945, 0.20127189, 0.15540285, 0.15565591, 0.14880875,\n",
       "        0.12958713, 0.16293715, 0.15683985, 0.17090572, 0.17573448,\n",
       "        0.11826551, 0.19876116, 0.14730244, 0.15623   , 0.10693538,\n",
       "        0.14979106, 0.1088849 , 0.17436149, 0.14044831, 0.19172086,\n",
       "        0.17436644, 0.11733785, 0.13815767, 0.16583494, 0.1404862 ,\n",
       "        0.18011723, 0.14429877, 0.20118932, 0.12770872, 0.11271177,\n",
       "        0.08483991, 0.19766203, 0.16104746, 0.14665086, 0.14907922,\n",
       "        0.17986553, 0.19599744, 0.20496702, 0.17394148, 0.16879343,\n",
       "        0.15325054, 0.13807988, 0.2003414 , 0.15860032, 0.19191269,\n",
       "        0.14690467, 0.10888998, 0.13561259, 0.13394664, 0.10500421,\n",
       "        0.17009078, 0.15435857, 0.1432643 , 0.12790605, 0.12484564,\n",
       "        0.19936964, 0.14647188, 0.13389953, 0.14360335, 0.16495115,\n",
       "        0.14042   , 0.19654887, 0.19084207, 0.09509471, 0.139426  ,\n",
       "        0.19622141, 0.14474207, 0.13294826, 0.21192282, 0.18202089,\n",
       "        0.13662713, 0.167128  , 0.19641349, 0.17761506, 0.19990133,\n",
       "        0.18528231, 0.14582664, 0.1263035 , 0.16141868, 0.16588828,\n",
       "        0.20159835, 0.19920017, 0.09049687, 0.12783978, 0.203654  ,\n",
       "        0.20688884, 0.14973985, 0.16504779, 0.2330403 , 0.17771051,\n",
       "        0.17636726, 0.25579493, 0.03746643, 0.16951836, 0.1713147 ,\n",
       "        0.20130944, 0.22620331, 0.11047398, 0.15359387, 0.22286227,\n",
       "        0.13922276, 0.108269  , 0.17049735, 0.1362254 , 0.17979246,\n",
       "        0.08900777, 0.15282246, 0.25489751, 0.14562887, 0.19643778,\n",
       "        0.19092811, 0.19870173, 0.13299405, 0.18927022, 0.14296982,\n",
       "        0.18438689, 0.08879411, 0.14860568, 0.205004  , 0.19886833,\n",
       "        0.17642563, 0.23251693, 0.11898816, 0.13434632, 0.16042536,\n",
       "        0.128439  , 0.19838812, 0.15337463, 0.14020915, 0.12932305,\n",
       "        0.09915257, 0.1724346 , 0.10411475, 0.21449309, 0.15472729,\n",
       "        0.10508347, 0.18044155, 0.14744738, 0.16311276, 0.17317923,\n",
       "        0.16991912, 0.19610293, 0.0972793 , 0.17629545, 0.1471919 ,\n",
       "        0.14676513, 0.20397354, 0.14412814, 0.18202584, 0.13591067,\n",
       "        0.1651364 , 0.08246029, 0.19831061, 0.1343246 , 0.15320261,\n",
       "        0.11474325, 0.13363781, 0.19764882, 0.16165203, 0.19007782,\n",
       "        0.11228162, 0.1163175 , 0.15046258, 0.12392447, 0.13006143,\n",
       "        0.20069974, 0.1216956 , 0.12536199, 0.15240946, 0.08798212,\n",
       "        0.09871728, 0.16721583, 0.16443598, 0.08516591, 0.18809075,\n",
       "        0.05891278, 0.13196665, 0.09891482, 0.13025887, 0.14812896,\n",
       "        0.14861836, 0.14583504, 0.13858597, 0.14796931, 0.1390294 ,\n",
       "        0.16107775, 0.12152014, 0.17521066, 0.22175625, 0.11559828,\n",
       "        0.18144084, 0.1291027 , 0.15498643, 0.18575251, 0.13708323,\n",
       "        0.18835085, 0.06648557, 0.08289039, 0.20611929, 0.17559979,\n",
       "        0.20798389, 0.18751447, 0.21768663, 0.17970844, 0.17558982,\n",
       "        0.12422009, 0.12652328, 0.1454431 , 0.21079849, 0.15770795,\n",
       "        0.16692272, 0.138401  , 0.13081154, 0.12694163, 0.08666114,\n",
       "        0.13146614, 0.14935156, 0.11755729, 0.19454746, 0.1800989 ,\n",
       "        0.15284284, 0.1571693 , 0.11509965, 0.20009209, 0.15430616,\n",
       "        0.19929085, 0.15787977, 0.11447564, 0.07619631, 0.14938002,\n",
       "        0.10979481, 0.21197475, 0.18036459, 0.19892831, 0.15719382,\n",
       "        0.15381788, 0.13747399, 0.12361347, 0.13519808, 0.15058101,\n",
       "        0.12950198, 0.11635929, 0.19975804, 0.18208619, 0.19524622,\n",
       "        0.15730764, 0.15497678, 0.16308524, 0.07047549, 0.10187073,\n",
       "        0.15589169, 0.11928346, 0.19296842, 0.15630454, 0.129613  ,\n",
       "        0.18418099, 0.18604413, 0.14992776, 0.17395961, 0.11196367,\n",
       "        0.18966563, 0.22755058, 0.17688385, 0.1240986 , 0.19018926,\n",
       "        0.08894429, 0.17451086, 0.12997076, 0.16236851, 0.17555958,\n",
       "        0.15774608, 0.17843802, 0.10490292, 0.17474867, 0.1355481 ,\n",
       "        0.14501664, 0.15622438, 0.18791704, 0.18527937, 0.19234222,\n",
       "        0.13156285, 0.18100263, 0.11235847, 0.14322783, 0.08276276,\n",
       "        0.08632609, 0.18238136, 0.17698449, 0.17706598, 0.19485415,\n",
       "        0.15452695, 0.13292874, 0.20898944, 0.18794822, 0.10582539,\n",
       "        0.14536673, 0.18860276, 0.15108737, 0.148225  , 0.20103054,\n",
       "        0.18358744, 0.13082675, 0.13142944, 0.13859836, 0.1139617 ,\n",
       "        0.23222535, 0.1913531 , 0.12333325, 0.16990274, 0.14662375,\n",
       "        0.13966088, 0.17399335, 0.09579048, 0.12329326, 0.15610885,\n",
       "        0.05850002, 0.14970445, 0.18087146, 0.13069224, 0.16880257,\n",
       "        0.16446936, 0.17536516, 0.19002712, 0.18673759, 0.2426221 ,\n",
       "        0.06823911, 0.1641169 , 0.18883166, 0.09707295, 0.17146712,\n",
       "        0.19783914, 0.17785336, 0.22300158, 0.14516672, 0.21199078,\n",
       "        0.14292028, 0.14292644, 0.18772106, 0.1222103 , 0.15566876,\n",
       "        0.17084208, 0.11398378, 0.06338566, 0.20215911, 0.14891771,\n",
       "        0.15333195, 0.24494943, 0.0842168 , 0.19728002, 0.18164369,\n",
       "        0.13131777, 0.14329753, 0.11208663, 0.12273685, 0.16429155,\n",
       "        0.15808539, 0.12802953, 0.18974566, 0.15027381, 0.20800169,\n",
       "        0.23611602, 0.1217694 , 0.12835637, 0.14970819, 0.15008888,\n",
       "        0.22190401, 0.12484138, 0.15758463, 0.11888174, 0.15408184,\n",
       "        0.20914594, 0.09647381, 0.179733  , 0.13282651, 0.16459007,\n",
       "        0.14757765, 0.15309046, 0.11971776, 0.14523073, 0.14119072,\n",
       "        0.15744721, 0.12382415, 0.13416049, 0.11625813, 0.1817596 ,\n",
       "        0.1230145 , 0.12054763, 0.11888429, 0.18453262, 0.2320172 ,\n",
       "        0.1060932 , 0.1221686 , 0.13845043, 0.12372887, 0.17676984,\n",
       "        0.1709397 , 0.21550992, 0.15839602, 0.16659156, 0.18392594,\n",
       "        0.18072288, 0.07512034, 0.20007635, 0.15558117, 0.18153704,\n",
       "        0.18407876, 0.12352849, 0.18157788, 0.13329327, 0.14719148,\n",
       "        0.10372016, 0.13452967, 0.12529879, 0.20304433, 0.13714064,\n",
       "        0.16227604, 0.15348352, 0.10188618, 0.12634188, 0.11439705,\n",
       "        0.13014033, 0.18720823, 0.20230985, 0.22885716, 0.18499706,\n",
       "        0.09006105, 0.15935123, 0.13440901, 0.19251375, 0.17441909,\n",
       "        0.17764614, 0.13489788, 0.19865436, 0.16394777, 0.24758312,\n",
       "        0.1977822 , 0.06868716, 0.15853375, 0.15966479, 0.10858374,\n",
       "        0.21423516, 0.17508635, 0.1105071 , 0.05053565, 0.19681999,\n",
       "        0.19318992, 0.10173572, 0.12978105, 0.13808481, 0.1961987 ,\n",
       "        0.17825882, 0.15743806, 0.16719551, 0.20619735, 0.11642874,\n",
       "        0.09165234, 0.18014601, 0.17607325, 0.15943311, 0.22587741,\n",
       "        0.15929254, 0.13373579, 0.22930729, 0.22652965, 0.10679558,\n",
       "        0.15628433, 0.16041945, 0.16969962, 0.15858565, 0.12402842,\n",
       "        0.15161831, 0.10158868, 0.15743813, 0.12628253, 0.2141419 ,\n",
       "        0.11091807, 0.19122432, 0.12634255, 0.19397403, 0.17775762,\n",
       "        0.21427349, 0.14884791, 0.12589617, 0.1576193 , 0.16376065,\n",
       "        0.20849754, 0.12169913, 0.1432197 , 0.11283486, 0.18872447,\n",
       "        0.26054942, 0.14877883, 0.18220269, 0.15810248, 0.188575  ,\n",
       "        0.2353503 , 0.16716108, 0.14621575, 0.12138842, 0.21200911,\n",
       "        0.12174006, 0.200328  , 0.08192202, 0.13832896, 0.15648719,\n",
       "        0.1916782 , 0.21217862, 0.13424232, 0.15768054, 0.04960478,\n",
       "        0.16890992, 0.18994209, 0.13158118, 0.15368648, 0.20539204,\n",
       "        0.16061585, 0.15600375, 0.1274725 , 0.19243367, 0.17925557,\n",
       "        0.07247708, 0.09197484, 0.15841797, 0.17948207, 0.19220848,\n",
       "        0.09920206, 0.12816374, 0.17929359, 0.1206962 , 0.20602088,\n",
       "        0.18669892, 0.06837632, 0.11727171, 0.13676237, 0.1677247 ,\n",
       "        0.20616947, 0.15999121, 0.15561739, 0.1772582 , 0.11813914,\n",
       "        0.13906811, 0.13477517, 0.08953448, 0.20746004, 0.14358623,\n",
       "        0.18709691, 0.10579684, 0.16696057, 0.1047208 , 0.15501256,\n",
       "        0.2517738 , 0.19387476, 0.17375446, 0.17973775, 0.2145483 ,\n",
       "        0.26001136, 0.11926658, 0.14426555, 0.14122826, 0.16403355,\n",
       "        0.12560713, 0.16114402, 0.16202563, 0.09987877, 0.17854461]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Test significance\n",
    "import multiprocessing\n",
    "\n",
    "bootstrap_significance_test(human_prefs, llm_prefs, n_cores=multiprocessing.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
