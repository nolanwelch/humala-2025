{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882885ad-b7d9-4586-a3e6-7d1dcb17544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31106c79-39ad-4a5e-878a-1e80edaa2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model', 'stimulus_number', 'trial', 'utterance',\n",
      "       'acceptability_rating'],\n",
      "      dtype='object')        stimulus_number        trial  acceptability_rating\n",
      "count      4590.000000  4590.000000           4590.000000\n",
      "mean        129.500000     2.000000              5.435294\n",
      "std          29.446656     0.816586              1.663857\n",
      "min          79.000000     1.000000              1.000000\n",
      "25%         104.000000     1.000000              5.000000\n",
      "50%         129.500000     2.000000              6.000000\n",
      "75%         155.000000     3.000000              7.000000\n",
      "max         180.000000     3.000000              7.000000\n",
      "Index(['participant', 'age', 'gender', 'education', 'aoa_english',\n",
      "       'aoa_spanish', 'cultural_id', 'blp', 'blp_history_english',\n",
      "       'blp_history_spanish', 'blp_use_english', 'blp_use_spanish',\n",
      "       'blp_proficiency_english', 'blp_proficiency_spanish',\n",
      "       'blp_attitudes_english', 'blp_attitudes_spanish', 'proficiency_english',\n",
      "       'proficiency_spanish', 'lextale_english', 'lextale_spanish', 'section',\n",
      "       'language', 'stimulus_number', 'structure', 'condition',\n",
      "       'lexicalization', 'rating'],\n",
      "      dtype='object')        participant          age  aoa_english  aoa_spanish          blp  \\\n",
      "count  1008.000000  1008.000000  1008.000000  1008.000000  1008.000000   \n",
      "mean   5108.428571    28.952381     2.523810     0.428571    40.149000   \n",
      "std    2379.056956     5.216820     2.443285     1.137454    39.616396   \n",
      "min    1522.000000    19.000000     0.000000     0.000000   -62.567000   \n",
      "25%    2943.000000    25.000000     0.000000     0.000000    23.248000   \n",
      "50%    4623.000000    31.000000     3.000000     0.000000    40.506000   \n",
      "75%    6176.000000    33.000000     5.000000     0.000000    61.028000   \n",
      "max    9915.000000    38.000000     7.000000     5.000000   128.043000   \n",
      "\n",
      "       blp_history_english  blp_history_spanish  blp_use_english  \\\n",
      "count          1008.000000          1008.000000      1008.000000   \n",
      "mean             98.761905            73.476190        33.809524   \n",
      "std              14.064360            16.658359         5.236362   \n",
      "min              64.000000            44.500000        21.000000   \n",
      "25%              89.000000            63.000000        30.000000   \n",
      "50%             103.000000            74.000000        35.000000   \n",
      "75%             110.000000            86.000000        37.000000   \n",
      "max             118.000000           101.000000        43.000000   \n",
      "\n",
      "       blp_use_spanish  blp_proficiency_english  blp_proficiency_spanish  \\\n",
      "count      1008.000000              1008.000000              1008.000000   \n",
      "mean         16.928571                22.666667                17.809524   \n",
      "std           8.543066                 1.459142                 3.789316   \n",
      "min           1.500000                20.000000                12.000000   \n",
      "25%          11.000000                21.000000                14.000000   \n",
      "50%          18.000000                23.000000                19.000000   \n",
      "75%          23.000000                24.000000                21.000000   \n",
      "max          35.500000                24.000000                24.000000   \n",
      "\n",
      "       blp_attitudes_english  blp_attitudes_spanish  proficiency_english  \\\n",
      "count            1008.000000            1008.000000          1008.000000   \n",
      "mean               21.285714              21.619048            36.238095   \n",
      "std                 3.508779               3.200936             2.224459   \n",
      "min                10.000000              10.000000            30.000000   \n",
      "25%                19.000000              21.000000            36.000000   \n",
      "50%                22.000000              22.000000            37.000000   \n",
      "75%                24.000000              24.000000            37.000000   \n",
      "max                24.000000              24.000000            39.000000   \n",
      "\n",
      "       proficiency_spanish  lextale_english  lextale_spanish  stimulus_number  \\\n",
      "count          1008.000000      1008.000000      1008.000000      1008.000000   \n",
      "mean             38.285714        82.916667        20.142857       122.750000   \n",
      "std               6.980588        20.569112        16.728079        35.515567   \n",
      "min              22.000000         0.000000        -1.000000        79.000000   \n",
      "25%              36.000000        75.000000        10.000000        90.750000   \n",
      "50%              38.000000        87.500000        12.000000       116.000000   \n",
      "75%              45.000000        96.250000        35.000000       148.000000   \n",
      "max              47.000000       100.000000        52.000000       180.000000   \n",
      "\n",
      "            rating  \n",
      "count  1008.000000  \n",
      "mean      6.512897  \n",
      "std       1.362657  \n",
      "min       1.000000  \n",
      "25%       7.000000  \n",
      "50%       7.000000  \n",
      "75%       7.000000  \n",
      "max       7.000000  \n"
     ]
    }
   ],
   "source": [
    "llm_ajt = pd.read_csv(\"../results.csv\")\n",
    "human_ajt = pd.read_csv(\"../human-results.csv\")\n",
    "\n",
    "print(llm_ajt.columns, llm_ajt.describe())\n",
    "print(human_ajt.columns, human_ajt.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdab267-7ef6-48ef-8fea-0f1ef4993cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairwise_preferences(df, annotator_col, stimulus_col, rating_col):\n",
    "    \"\"\"\n",
    "    Generate pairwise preferences for each annotator\n",
    "    \"\"\"\n",
    "    preferences = []\n",
    "    \n",
    "    for annotator in df[annotator_col].unique():\n",
    "        annotator_data = df[df[annotator_col] == annotator]\n",
    "        \n",
    "        # Get all pairs of stimuli rated by this annotator\n",
    "        for i, row1 in annotator_data.iterrows():\n",
    "            for j, row2 in annotator_data.iterrows():\n",
    "                if i >= j:  # Avoid duplicates and self-comparisons\n",
    "                    continue\n",
    "                \n",
    "                stimulus_i = row1[stimulus_col]\n",
    "                stimulus_j = row2[stimulus_col]\n",
    "                rating_i = row1[rating_col]\n",
    "                rating_j = row2[rating_col]\n",
    "                \n",
    "                # Skip ties\n",
    "                if rating_i == rating_j:\n",
    "                    continue\n",
    "                \n",
    "                # Record preference\n",
    "                if rating_i > rating_j:\n",
    "                    preferences.append({\n",
    "                        'annotator_id': annotator,\n",
    "                        'stimulus_i': stimulus_i,\n",
    "                        'stimulus_j': stimulus_j,\n",
    "                        'preference': f\"{stimulus_i}>{stimulus_j}\"\n",
    "                    })\n",
    "                else:\n",
    "                    preferences.append({\n",
    "                        'annotator_id': annotator,\n",
    "                        'stimulus_i': stimulus_i,\n",
    "                        'stimulus_j': stimulus_j,\n",
    "                        'preference': f\"{stimulus_j}>{stimulus_i}\"\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2300e80-dc8f-4a7f-b1e4-31ecc0c961de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_agreement(preferences_df):\n",
    "    \"\"\"\n",
    "    Calculate pairwise agreement within the group\n",
    "    \"\"\"\n",
    "    # Find stimulus pairs that multiple annotators evaluated\n",
    "    pair_counts = preferences_df.groupby(['stimulus_i', 'stimulus_j']).size()\n",
    "    shared_pairs = pair_counts[pair_counts > 1].index\n",
    "    \n",
    "    agreements = []\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    for stimulus_i, stimulus_j in shared_pairs:\n",
    "        pair_prefs = preferences_df[\n",
    "            (preferences_df['stimulus_i'] == stimulus_i) & \n",
    "            (preferences_df['stimulus_j'] == stimulus_j)\n",
    "        ]\n",
    "        \n",
    "        if len(pair_prefs) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Check agreement for all annotator pairs who rated this stimulus pair\n",
    "        annotators = pair_prefs['annotator_id'].tolist()\n",
    "        preferences = pair_prefs['preference'].tolist()\n",
    "        \n",
    "        for i in range(len(annotators)):\n",
    "            for j in range(i + 1, len(annotators)):\n",
    "                total_comparisons += 1\n",
    "                if preferences[i] == preferences[j]:\n",
    "                    agreements.append(1)\n",
    "                else:\n",
    "                    agreements.append(0)\n",
    "    \n",
    "    if total_comparisons == 0:\n",
    "        return 0.0, 0\n",
    "    \n",
    "    agreement_rate = np.mean(agreements)\n",
    "    return agreement_rate, total_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8db88c-0bd2-41fd-8256-9e986d4b7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_group_agreements(human_prefs, llm_prefs):\n",
    "    \"\"\"\n",
    "    Compare group-level agreement scores\n",
    "    \"\"\"\n",
    "    human_agreement, human_comps = calculate_pairwise_agreement(human_prefs)\n",
    "    llm_agreement, llm_comps = calculate_pairwise_agreement(llm_prefs)\n",
    "    \n",
    "    print(f\"Human Agreement: {human_agreement:.3f} ({human_comps} comparisons)\")\n",
    "    print(f\"LLM Agreement: {llm_agreement:.3f} ({llm_comps} comparisons)\")\n",
    "    print(f\"Difference: {llm_agreement - human_agreement:.3f}\")\n",
    "    \n",
    "    return human_agreement, llm_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35ee3f3-64f4-4c7e-a2a4-883e36f70777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def bootstrap_significance_test(human_prefs, llm_prefs, n_bootstrap=1000):\n",
    "    \"\"\"\n",
    "    Step 4: Statistical significance testing via bootstrap\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    def bootstrap_agreement(prefs_df):\n",
    "        # Resample annotators with replacement\n",
    "        annotators = prefs_df['annotator_id'].unique()\n",
    "        sampled_annotators = np.random.choice(annotators, size=len(annotators), replace=True)\n",
    "        \n",
    "        # Create bootstrap sample\n",
    "        bootstrap_prefs = []\n",
    "        for annotator in sampled_annotators:\n",
    "            annotator_prefs = prefs_df[prefs_df['annotator_id'] == annotator].copy()\n",
    "            bootstrap_prefs.append(annotator_prefs)\n",
    "        \n",
    "        if bootstrap_prefs:\n",
    "            bootstrap_df = pd.concat(bootstrap_prefs, ignore_index=True)\n",
    "            agreement, _ = calculate_pairwise_agreement(bootstrap_df)\n",
    "            return agreement\n",
    "        return 0.0\n",
    "    \n",
    "    # Generate bootstrap samples\n",
    "    human_boots = []\n",
    "    llm_boots = []\n",
    "    \n",
    "    print(\"Running bootstrap analysis...\")\n",
    "    for _ in tqdm(range(n_bootstrap), desc=\"Bootstrap iterations\"):\n",
    "        human_boots.append(bootstrap_agreement(human_prefs))\n",
    "        llm_boots.append(bootstrap_agreement(llm_prefs))\n",
    "    \n",
    "    # Calculate difference distribution\n",
    "    diff_boots = np.array(llm_boots) - np.array(human_boots)\n",
    "    \n",
    "    # Two-tailed p-value\n",
    "    observed_diff = np.mean(llm_boots) - np.mean(human_boots)\n",
    "    p_value = np.mean(np.abs(diff_boots) >= np.abs(observed_diff))\n",
    "    \n",
    "    print(f\"Bootstrap p-value: {p_value:.3f}\")\n",
    "    print(f\"95% CI for difference: [{np.percentile(diff_boots, 2.5):.3f}, {np.percentile(diff_boots, 97.5):.3f}]\")\n",
    "    \n",
    "    return p_value, diff_boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ed9e16-3ea0-4381-baf4-6c1f323036bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate pairwise preferences\n",
    "human_prefs = generate_pairwise_preferences(\n",
    "    human_ajt, 'participant', 'stimulus_number', 'rating'\n",
    ")\n",
    "llm_prefs = generate_pairwise_preferences(\n",
    "    llm_ajt, 'model', 'stimulus_number', 'acceptability_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14d5769-0ba9-4926-909f-8d9962ad9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Agreement: 0.672 (16342 comparisons)\n",
      "LLM Agreement: 0.840 (22027452 comparisons)\n",
      "Difference: 0.168\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Compare agreements\n",
    "human_agreement, llm_agreement = compare_group_agreements(human_prefs, llm_prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dab1190-d759-4e78-ad53-5fcf594b675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstrap analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap iterations:   0%|▏                                                                                                               | 2/1000 [00:31<4:23:25, 15.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Test significance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbootstrap_significance_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_prefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_prefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36mbootstrap_significance_test\u001b[0;34m(human_prefs, llm_prefs, n_bootstrap)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_bootstrap), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBootstrap iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     33\u001b[0m     human_boots\u001b[38;5;241m.\u001b[39mappend(bootstrap_agreement(human_prefs))\n\u001b[0;32m---> 34\u001b[0m     llm_boots\u001b[38;5;241m.\u001b[39mappend(\u001b[43mbootstrap_agreement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_prefs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate difference distribution\u001b[39;00m\n\u001b[1;32m     37\u001b[0m diff_boots \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(llm_boots) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39marray(human_boots)\n",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m, in \u001b[0;36mbootstrap_significance_test.<locals>.bootstrap_agreement\u001b[0;34m(prefs_df)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bootstrap_prefs:\n\u001b[1;32m     22\u001b[0m     bootstrap_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(bootstrap_prefs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m     agreement, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pairwise_agreement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrap_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agreement\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mcalculate_pairwise_agreement\u001b[0;34m(preferences_df)\u001b[0m\n\u001b[1;32m     10\u001b[0m total_comparisons \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stimulus_i, stimulus_j \u001b[38;5;129;01min\u001b[39;00m shared_pairs:\n\u001b[1;32m     13\u001b[0m     pair_prefs \u001b[38;5;241m=\u001b[39m preferences_df[\n\u001b[1;32m     14\u001b[0m         (preferences_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstimulus_i\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m stimulus_i) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m---> 15\u001b[0m         (\u001b[43mpreferences_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstimulus_j\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstimulus_j\u001b[49m)\n\u001b[1;32m     16\u001b[0m     ]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pair_prefs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/ops/array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/projects/nlp-alignment/.venv/lib64/python3.13/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 3: Test significance\n",
    "bootstrap_significance_test(human_prefs, llm_prefs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
